import uvicorn
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from backend.agent import get_sql_agent_graph

# ---------------------------------------------------------
# 1. Initialize FastAPI Application
# ---------------------------------------------------------
app = FastAPI(
    title="Enterprise Knowledge Nexus API",
    description="HTTP Interface for the SQL-based RAG Agent",
    version="1.0"
)

# ---------------------------------------------------------
# 2. Define Data Models (Pydantic)
# ---------------------------------------------------------

# The structure of the data sent BY the user
class ChatRequest(BaseModel):
    query: str
    thread_id: str = "default_thread" # Used for conversation memory

# The structure of the data sent BACK to the user
class ChatResponse(BaseModel):
    response: str

# ---------------------------------------------------------
# 3. Initialize the Agent
# ---------------------------------------------------------
# We load the agent graph once when the server starts to avoid overhead per request
print("ğŸ¤– Loading Agent Graph...")
agent_graph = get_sql_agent_graph()
print("âœ… Agent Graph loaded.")

# ---------------------------------------------------------
# 4. Define API Endpoints
# ---------------------------------------------------------
async def chat_endpoint(request: ChatRequest):
    """
    Main endpoint: Receives a user query, runs the Agent, and returns the response.
    """
    try:
        # 1. Construct the input for LangGraph
        # æˆ‘ä»¬æŠŠç”¨æˆ·å‘æ¥çš„ request.query åŒ…è£…æˆ LangGraph éœ€è¦çš„æ¶ˆæ¯æ ¼å¼
        # æ ¼å¼: {"messages": [("user", "ç”¨æˆ·çš„å…·ä½“é—®é¢˜")]}
        inputs = {"messages": [("user", request.query)]}
        
        # 2. Construct the configuration
        # æˆ‘ä»¬æŠŠç”¨æˆ·å‘æ¥çš„ request.thread_id ä¼ ç»™ MemorySaver
        config = {"configurable": {"thread_id": request.thread_id}}
        
        # 3. Invoke the Agent
        # æŠŠåˆšæ‰æ‰“åŒ…å¥½çš„ inputs å’Œ config æ‰”ç»™å¤§è„‘
        result = agent_graph.invoke(inputs, config)
        
        # 4. Extract the final AI response
        # result["messages"] æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œ[-1] è¡¨ç¤ºå–æœ€åä¸€æ¡ï¼ˆä¹Ÿå°±æ˜¯ AI çš„å›å¤ï¼‰
        # .content è¡¨ç¤ºå–é‡Œé¢çš„æ–‡å­—å†…å®¹
        final_content = result["messages"][-1].content
        
        # Return the result
        return ChatResponse(response=final_content)
        
    except Exception as e:
        # Log the error and return a 500 status code
        print(f"âŒ Error processing request: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ---------------------------------------------------------
# 5. Entry Point for Local Testing
# ---------------------------------------------------------
if __name__ == "__main__":
    # This allows you to run the server via: python -m backend.server
    uvicorn.run(app, host="127.0.0.1", port=8000)

